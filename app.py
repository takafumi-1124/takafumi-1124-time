# ============================================
# ESGæŠ•è³‡æ„æ€æ±ºå®šã‚¢ãƒ—ãƒªï¼ˆStreamlit Cloudå¯¾å¿œç‰ˆï¼‰
# ============================================

import streamlit as st
import pandas as pd
import numpy as np
import itertools
import matplotlib.pyplot as plt
import matplotlib as mpl

# --- seaborné–¢é€£ã‚¨ãƒ©ãƒ¼å¯¾ç­– ---
mpl.rcParams.update(mpl.rcParamsDefault)
try:
    plt.style.use("default")
except OSError:
    pass

# âœ… ã“ã“ã§PyPortfolioOptã‚’å¾Œã‹ã‚‰importï¼ˆé †ç•ªãŒé‡è¦ï¼‰
from pypfopt import expected_returns, risk_models, EfficientFrontier, plotting
import japanize_matplotlib
import gspread
from google.oauth2 import service_account



# ============================================
# é–¢æ•°å®šç¾©
# ============================================

def get_dynamic_scale_labels(left: str, right: str):
    return [
        f"{left}ãŒåœ§å€’çš„ã«é‡è¦", f"{left}ãŒéå¸¸ã«é‡è¦", f"{left}ãŒã‹ãªã‚Šé‡è¦", f"{left}ãŒå°‘ã—é‡è¦",
        "åŒã˜ãã‚‰ã„é‡è¦",
        f"{right}ãŒå°‘ã—é‡è¦", f"{right}ãŒã‹ãªã‚Šé‡è¦", f"{right}ãŒéå¸¸ã«é‡è¦", f"{right}ãŒåœ§å€’çš„ã«é‡è¦"
    ]

def get_dynamic_label_to_value(left: str, right: str):
    values = [9, 7, 5, 3, 1, 1/3, 1/5, 1/7, 1/9]
    labels = get_dynamic_scale_labels(left, right)
    return dict(zip(labels, values))

def ahp_calculation(pairwise_matrix):
    n = pairwise_matrix.shape[0]
    geo_means = np.prod(pairwise_matrix, axis=1) ** (1/n)
    priorities = geo_means / np.sum(geo_means)
    weighted_sum = np.dot(pairwise_matrix, priorities)
    lamda_max = np.sum(weighted_sum / priorities) / n
    CI = (lamda_max - n) / (n - 1)
    RI_dict = {
        1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90,
        5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45
    }
    CR = CI / RI_dict[n]
    return priorities, CR


# ============================================
# Streamlit ãƒšãƒ¼ã‚¸è¨­å®š
# ============================================

st.set_page_config(page_title="ESGæŠ•è³‡æ„æ€æ±ºå®šã‚µã‚¤ãƒˆ", layout="centered")
st.title("ğŸŒ± ESGæŠ•è³‡æ„æ€æ±ºå®šã‚µã‚¤ãƒˆ")

tabs = st.tabs(["â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±", "â‘¡ Big Five è¨ºæ–­", "â‘¢ ESGå„ªå…ˆåº¦æ¸¬å®š", "â‘£ æŠ•è³‡ææ¡ˆ"])
all_priorities = {}


# ============================================
# â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›
# ============================================

with tabs[0]:
    st.header("ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›")
    name = st.text_input("åå‰", key="name")
    age = st.number_input("å¹´é½¢", 10, 100, 20, key="age")
    job = st.text_input("è·æ¥­", placeholder="ä¾‹ï¼šå¤§å­¦ç”Ÿ")


# ============================================
# â‘¡ Big Fiveè¨ºæ–­
# ============================================

with tabs[1]:
    st.header("Big Five è¨ºæ–­")
    st.markdown("å„é …ç›®ã«ã¤ã„ã¦ã€1ã€œ5ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚")

    bigfive_items = [
        ("ç„¡å£ãª", "å¤–å‘æ€§", True), ("ç¤¾äº¤çš„", "å¤–å‘æ€§", False), ("è©±å¥½ã", "å¤–å‘æ€§", False),
        ("å¤–å‘çš„", "å¤–å‘æ€§", False), ("é™½æ°—ãª", "å¤–å‘æ€§", False),
        ("ã„ã„åŠ æ¸›ãª", "èª å®Ÿæ€§", True), ("å‡ å¸³é¢", "èª å®Ÿæ€§", False),
        ("ä¸å®‰ã«ãªã‚Šã‚„ã™ã„", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("å¿ƒé…æ€§", "æƒ…ç·’ä¸å®‰å®šæ€§", False),
        ("å¤šæ‰ã®", "é–‹æ”¾æ€§", False), ("ç‹¬å‰µçš„ãª", "é–‹æ”¾æ€§", True),
        ("çŸ­æ°—", "èª¿å’Œæ€§", True), ("æ¸©å’Œãª", "èª¿å’Œæ€§", False),
    ]

    scores = {}
    for item, trait, reverse in bigfive_items:
        val = st.slider(f"{item}", 1, 5, 3, key=f"bf_{item}")
        if reverse:
            val = 6 - val
        scores.setdefault(trait, []).append(val)

    trait_scores = {k: np.mean(v) for k, v in scores.items()}
    st.dataframe(pd.DataFrame(trait_scores.items(), columns=["æ€§æ ¼ç‰¹æ€§", "ã‚¹ã‚³ã‚¢"]))


# ============================================
# â‘¢ AHPï¼šESGå„ªå…ˆåº¦æ¸¬å®š
# ============================================

with tabs[2]:
    st.header("ESGå„ªå…ˆåº¦æ¸¬å®š")

    labels_main = ['ç’°å¢ƒ', 'ç¤¾ä¼š', 'ã‚¬ãƒãƒŠãƒ³ã‚¹']
    matrix_main = np.ones((3, 3))

    for i, row in enumerate(labels_main):
        for j, col in enumerate(labels_main):
            if i < j:
                labels = get_dynamic_scale_labels(row, col)
                mapping = get_dynamic_label_to_value(row, col)
                selected = st.select_slider(f"{row} vs {col}", options=labels, value="åŒã˜ãã‚‰ã„é‡è¦")
                matrix_main[i][j] = mapping[selected]
                matrix_main[j][i] = 1 / mapping[selected]

    priorities_main, cr_main = ahp_calculation(matrix_main)
    st.dataframe(pd.DataFrame({"é …ç›®": labels_main, "å„ªå…ˆåº¦": priorities_main}))
    st.write(f"æ•´åˆæ€§æ¯”ç‡ (CR): {cr_main:.3f}")

    for group_name, group_items in {
        "ç’°å¢ƒ": ['æ°—å€™å¤‰å‹•', 'è³‡æºå¾ªç’°ãƒ»å¾ªç’°çµŒæ¸ˆ', 'ç”Ÿç‰©å¤šæ§˜æ€§', 'è‡ªç„¶è³‡æº'],
        "ç¤¾ä¼š": ['äººæ¨©ãƒ»ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³', 'é›‡ç”¨ãƒ»åŠ´åƒæ…£è¡Œ', 'å¤šæ§˜æ€§ãƒ»å…¬å¹³æ€§'],
        "ã‚¬ãƒãƒŠãƒ³ã‚¹": ['å–ç· å½¹ä¼šæ§‹æˆãƒ»å°‘æ•°æ ªä¸»ä¿è­·', 'çµ±æ²»ã¨ãƒªã‚¹ã‚¯ç®¡ç†']
    }.items():
        st.subheader(f"{group_name}ã®å„ªå…ˆåº¦æ¸¬å®š")
        size = len(group_items)
        matrix = np.ones((size, size))
        for i in range(size):
            for j in range(i + 1, size):
                labels = get_dynamic_scale_labels(group_items[i], group_items[j])
                mapping = get_dynamic_label_to_value(group_items[i], group_items[j])
                selected = st.select_slider(f"{group_items[i]} vs {group_items[j]}", options=labels, value="åŒã˜ãã‚‰ã„é‡è¦")
                matrix[i][j] = mapping[selected]
                matrix[j][i] = 1 / mapping[selected]

        priorities, cr = ahp_calculation(matrix)
        st.dataframe(pd.DataFrame({"é …ç›®": group_items, "å„ªå…ˆåº¦": priorities}))
        st.write(f"æ•´åˆæ€§æ¯”ç‡ (CR): {cr:.3f}")
        all_priorities[group_name] = dict(zip(group_items, priorities))

    st.divider()
    st.subheader("AHPçµæœã¾ã¨ã‚")
    top_category = labels_main[np.argmax(priorities_main)]
    if top_category in all_priorities:
        top_sub = max(all_priorities[top_category].items(), key=lambda x: x[1])[0]
        st.markdown(f"ã‚ãªãŸãŒæœ€ã‚‚é‡è¦–ã—ã¦ã„ã‚‹ã®ã¯ **{top_category}** ã§ã€ãã®ä¸­ã§ã‚‚ **{top_sub}** ã§ã™ã€‚")


# ============================================
# â‘£ æŠ•è³‡ææ¡ˆ & ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä¿å­˜
# ============================================

@st.cache_data
def load_data():
    return pd.read_excel("ã‚¹ã‚³ã‚¢ä»˜ãESGãƒ‡ãƒ¼ã‚¿ - ã‚³ãƒ”ãƒ¼.xlsx", sheet_name="Sheet1")

df = load_data()

# --- âœ… Google Sheetsèªè¨¼ï¼ˆSecretsä½¿ç”¨ï¼‰ ---
scope = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]
creds = service_account.Credentials.from_service_account_info(
    st.secrets["gcp_service_account"],
    scopes=scope
)
gc = gspread.authorize(creds)
st.write("âœ… Googleèªè¨¼ã«æˆåŠŸã—ã¾ã—ãŸï¼")

spreadsheet = gc.open_by_url("https://docs.google.com/spreadsheets/d/1WVOWgp5Q4TlQu_HhX3TJ5F0beSw1zkcZfcxiiVhn3Yk/edit?gid=0#gid=0")
worksheet = spreadsheet.sheet1


# --- æŠ•è³‡ææ¡ˆçµæœ ---
with tabs[3]:
    st.header("æŠ•è³‡å…ˆææ¡ˆ")
    st.subheader("æŠ•è³‡å…ˆã®ä¼æ¥­")

    dummy_csr = df.copy()
    dummy_csr["ã‚¹ã‚³ã‚¢"] = np.random.rand(len(df))
    result = dummy_csr.sort_values("ã‚¹ã‚³ã‚¢", ascending=False).head(3)
    st.dataframe(result[["ç¤¾å", "ã‚¹ã‚³ã‚¢"]])

    if st.button("çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜"):
        row_data = [
            name,
            age,
            job,
            trait_scores.get("å¤–å‘æ€§", 0),
            trait_scores.get("èª å®Ÿæ€§", 0),
            trait_scores.get("æƒ…ç·’ä¸å®‰å®šæ€§", 0),
            trait_scores.get("é–‹æ”¾æ€§", 0),
            trait_scores.get("èª¿å’Œæ€§", 0),
            ", ".join(result["ç¤¾å"].tolist())
        ]
        worksheet.append_row(row_data, value_input_option="USER_ENTERED")
        st.success("âœ… çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜ã—ã¾ã—ãŸï¼")

