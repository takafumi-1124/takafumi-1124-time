import streamlit as st
import pandas as pd
import numpy as np
import itertools
import streamlit as st
import pandas as pd
import numpy as np
import itertools
# ğŸ”½ ã“ã“ã«è¿½åŠ ã—ã¦ãã ã•ã„
# === seaborn-deepã‚¨ãƒ©ãƒ¼å®Œå…¨å¯¾ç­– ===
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib.style as mstyle
_original_style_use = plt.style.use

def safe_style_use(style_name):
    if style_name == "seaborn-deep":
        print("âš  seaborn-deep style skipped (not available on Streamlit Cloud).")
        return
    return _original_style_use(style_name)

plt.style.use = safe_style_use
mpl.style.use = safe_style_use

# ğŸ”¼ ã“ã“ã¾ã§ã‚’è¿½åŠ 

from pypfopt import expected_returns, risk_models, EfficientFrontier, plotting
import japanize_matplotlib

import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns  # â† seabornã‚’å…ˆã«èª­ã¿è¾¼ã‚€

# --- seaborn-deep ã‚¨ãƒ©ãƒ¼å¯¾ç­– ---
try:
    plt.style.use("default")  # seabornç³»ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è§£é™¤
    mpl.rcParams.update(mpl.rcParamsDefault)
    sns.set_style("whitegrid")  # seabornå´ã‚‚å®‰å…¨ãªã‚¹ã‚¿ã‚¤ãƒ«ã«å›ºå®š
except OSError:
    pass

# --- PyPortfolioOpt èª­ã¿è¾¼ã¿å‰ã«å¯¾ç­–ã‚’é©ç”¨ ---
import matplotlib.style as mstyle
mstyle.available = ["default", "classic"]  # seaborn-deepã‚’ç„¡åŠ¹åŒ–ãƒªã‚¹ãƒˆã«ã™ã‚‹

import pypfopt.plotting as pplot  # â† ã“ã‚ŒãŒå•é¡Œã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
pplot.plt = plt  # pltã‚’ä¸Šæ›¸ã

# --- ãã®ä»–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from pypfopt import expected_returns, risk_models, EfficientFrontier
import japanize_matplotlib
import gspread
from oauth2client.service_account import ServiceAccountCredentials


# âœ… seabornã‚’å¼·åˆ¶çš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆPyPortfolioOptãŒæš—é»™çš„ã«å‘¼ã¶ãŸã‚ï¼‰
import seaborn as sns
sns.set_style("whitegrid")



# ã‚¹ã‚±ãƒ¼ãƒ«ç”Ÿæˆ
def get_dynamic_scale_labels(left: str, right: str):
    return [
        f"{left}ãŒåœ§å€’çš„ã«é‡è¦", f"{left}ãŒéå¸¸ã«é‡è¦", f"{left}ãŒã‹ãªã‚Šé‡è¦", f"{left}ãŒå°‘ã—é‡è¦",
        "åŒã˜ãã‚‰ã„é‡è¦",
        f"{right}ãŒå°‘ã—é‡è¦", f"{right}ãŒã‹ãªã‚Šé‡è¦", f"{right}ãŒéå¸¸ã«é‡è¦", f"{right}ãŒåœ§å€’çš„ã«é‡è¦"
    ]

def get_dynamic_label_to_value(left: str, right: str):
    values = [9, 7, 5, 3, 1, 1/3, 1/5, 1/7, 1/9]
    labels = get_dynamic_scale_labels(left, right)
    return dict(zip(labels, values))

def ahp_calculation(pairwise_matrix):
    n = pairwise_matrix.shape[0]
    geo_means = np.prod(pairwise_matrix, axis=1) ** (1/n)
    priorities = geo_means / np.sum(geo_means)

    weighted_sum = np.dot(pairwise_matrix, priorities)
    lamda_max = np.sum(weighted_sum / priorities) / n
    CI = (lamda_max - n) / (n - 1)

    RI_dict = {
        1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90,
        5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45
    }
    CR = CI / RI_dict[n]
    return priorities, CR


st.set_page_config(page_title="ESGæŠ•è³‡æ„æ€æ±ºå®š", layout="centered")
# st.markdown(
#     """
#     <meta http-equiv="Content-Language" content="ja">
#     <meta name="google" content="notranslate">
#     <style>
#     body, div, span, table {
#         class: notranslate;
#     }
#     </style>
#     """,
#     unsafe_allow_html=True
# )
st.title("\U0001f331 ESGæŠ•è³‡æ„æ€æ±ºå®šã‚µã‚¤ãƒˆ")

tabs = st.tabs(["â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±", "â‘¡ Big Five è¨ºæ–­", "â‘¢ ESGå„ªå…ˆåº¦æ¸¬å®š", "â‘£ æŠ•è³‡ææ¡ˆ"])
all_priorities = {}

# â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
with tabs[0]:
    st.header("ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›")
    name = st.text_input("åå‰", key="name")
    age = st.number_input("å¹´é½¢", 10, 100, 20, key="age")
    job = st.text_input("ã‚ãªãŸã®è·æ¥­ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šå¤§å­¦ç”Ÿ")

# â‘¡ Big Five
with tabs[1]:
    st.header("Big Five è¨ºæ–­")
    st.markdown("ä»¥ä¸‹ã®å„é …ç›®ã«ã¤ã„ã¦ã€ã€Œéå¸¸ã«å½“ã¦ã¯ã¾ã‚‹ï¼ˆ5ï¼‰ã€ã‹ã‚‰ã€Œã¾ã£ãŸãå½“ã¦ã¯ã¾ã‚‰ãªã„ï¼ˆ1ï¼‰ã€ã¾ã§ã®5æ®µéšã§è©•ä¾¡ã—ã¦ãã ã•ã„")

    bigfive_items = [
        ("ç„¡å£ãª", "å¤–å‘æ€§", True), ("ç¤¾äº¤çš„", "å¤–å‘æ€§", False), ("è©±å¥½ã", "å¤–å‘æ€§", False),
        ("å¤–å‘çš„", "å¤–å‘æ€§", False), ("é™½æ°—ãª", "å¤–å‘æ€§", False),
        ("ã„ã„åŠ æ¸›ãª", "èª å®Ÿæ€§", True), ("ãƒ«ãƒ¼ã‚ºãª", "èª å®Ÿæ€§", True), ("æˆã‚Šè¡Œãã¾ã‹ã›", "èª å®Ÿæ€§", True),
        ("æ€ æƒ°ãª", "èª å®Ÿæ€§", False), ("è¨ˆç”»æ€§ã®ã‚ã‚‹", "èª å®Ÿæ€§", False), ("è»½ç‡ãª", "èª å®Ÿæ€§", False),
        ("å‡ å¸³é¢", "èª å®Ÿæ€§", False),
        ("ä¸å®‰ã«ãªã‚Šã‚„ã™ã„", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("å¿ƒé…æ€§", "æƒ…ç·’ä¸å®‰å®šæ€§", False),
        ("å¼±æ°—ã«ãªã‚‹", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("ç·Šå¼µã—ã‚„ã™ã„", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("æ†‚é¬±ãª", "æƒ…ç·’ä¸å®‰å®šæ€§", False),
        ("å¤šæ‰ã®", "é–‹æ”¾æ€§", False), ("é€²æ­©çš„", "é–‹æ”¾æ€§", False), ("ç‹¬å‰µçš„ãª", "é–‹æ”¾æ€§", True),
        ("é ­ã®å›è»¢ã®é€Ÿã„", "é–‹æ”¾æ€§", False), ("èˆˆå‘³ã®åºƒã„", "é–‹æ”¾æ€§", False), ("å¥½å¥‡å¿ƒãŒå¼·ã„", "é–‹æ”¾æ€§", False),
        ("çŸ­æ°—", "èª¿å’Œæ€§", True), ("æ€’ã‚Šã£ã½ã„", "èª¿å’Œæ€§", True), ("æ¸©å’Œãª", "èª¿å’Œæ€§", False),
        ("å¯›å¤§ãª", "èª¿å’Œæ€§", False), ("è‡ªå·±ä¸­å¿ƒçš„", "èª¿å’Œæ€§", True), ("è¦ªåˆ‡ãª", "èª¿å’Œæ€§", False),
    ]

    scores = {}
    for item, trait, reverse in bigfive_items:
        val = st.slider(f"{item}", 1, 5, 3, key=f"bf_{item}")
        if reverse:
            val = 6 - val
        scores.setdefault(trait, []).append(val)

    trait_scores = {k: np.mean(v) for k, v in scores.items()}
    st.subheader("Big Five ã‚¹ã‚³ã‚¢")
    st.dataframe(pd.DataFrame(trait_scores.items(), columns=["æ€§æ ¼ç‰¹æ€§", "ã‚¹ã‚³ã‚¢"]))

# â‘¢ AHP
with tabs[2]:
    st.header("ESGå„ªå…ˆåº¦æ¸¬å®š")
    st.markdown("""
    ä»¥ä¸‹ã®é …ç›®ã§ã¯ã€2ã¤ã®è¦ç´ ãŒä¸¦ã‚“ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚  
    ãƒãƒ¼ã®ä½ç½®ã‚’å·¦å³ã«å‹•ã‹ã—ã¦ã€ã©ã¡ã‚‰ã‚’ã©ã®ç¨‹åº¦å„ªå…ˆã™ã‚‹ã‹ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚  

    - å·¦ã«å‹•ã‹ã™ â†’ å·¦å´ã®è¦ç´ ã‚’ã‚ˆã‚Šé‡è¦–  
    - å³ã«å‹•ã‹ã™ â†’ å³å´ã®è¦ç´ ã‚’ã‚ˆã‚Šé‡è¦–  
    - çœŸã‚“ä¸­ â†’ ã€ŒåŒã˜ãã‚‰ã„é‡è¦ã€
    """)


    labels_main = ['ç’°å¢ƒ', 'ç¤¾ä¼š', 'ã‚¬ãƒãƒŠãƒ³ã‚¹']
    matrix_main = np.ones((3, 3))

    for i, row in enumerate(labels_main):
        for j, col in enumerate(labels_main):
            if i < j:
                labels = get_dynamic_scale_labels(row, col)
                mapping = get_dynamic_label_to_value(row, col)
                selected = st.select_slider(
                    f"{row} vs {col}", options=labels,
                    key=f"main_{row}_{col}", value="åŒã˜ãã‚‰ã„é‡è¦"
                )
                matrix_main[i][j] = mapping[selected]
                matrix_main[j][i] = 1 / mapping[selected]

    priorities_main, cr_main = ahp_calculation(matrix_main)
    st.dataframe(pd.DataFrame({"é …ç›®": labels_main, "å„ªå…ˆåº¦": priorities_main}))
    st.write(f"æ•´åˆæ€§æ¯”ç‡ (CR): {cr_main:.3f}")

    for group_name, group_items in {
        "ç’°å¢ƒ": ['æ°—å€™å¤‰å‹•', 'è³‡æºå¾ªç’°ãƒ»å¾ªç’°çµŒæ¸ˆ', 'ç”Ÿç‰©å¤šæ§˜æ€§', 'è‡ªç„¶è³‡æº'],
        "ç¤¾ä¼š": ['äººæ¨©ãƒ»ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³', 'é›‡ç”¨ãƒ»åŠ´åƒæ…£è¡Œ', 'å¤šæ§˜æ€§ãƒ»å…¬å¹³æ€§'],
        "ã‚¬ãƒãƒŠãƒ³ã‚¹": ['å–ç· å½¹ä¼šæ§‹æˆãƒ»å°‘æ•°æ ªä¸»ä¿è­·', 'çµ±æ²»ã¨ãƒªã‚¹ã‚¯ç®¡ç†']
    }.items():
        st.subheader(f"{group_name}ã®å„ªå…ˆåº¦æ¸¬å®š")
        size = len(group_items)
        matrix = np.ones((size, size))

        for i in range(size):
            for j in range(i + 1, size):
                labels = get_dynamic_scale_labels(group_items[i], group_items[j])
                mapping = get_dynamic_label_to_value(group_items[i], group_items[j])
                selected = st.select_slider(
                    f"{group_items[i]} vs {group_items[j]}",
                    options=labels,
                    key=f"{group_name}_{i}_{j}",
                    value="åŒã˜ãã‚‰ã„é‡è¦"
                )
                matrix[i][j] = mapping[selected]
                matrix[j][i] = 1 / mapping[selected]

        priorities, cr = ahp_calculation(matrix)
        st.dataframe(pd.DataFrame({"é …ç›®": group_items, "å„ªå…ˆåº¦": priorities}))
        st.write(f"æ•´åˆæ€§æ¯”ç‡ (CR): {cr:.3f}")
        all_priorities[group_name] = dict(zip(group_items, priorities))


    st.divider()  # åŒºåˆ‡ã‚Šç·š

    st.subheader("AHPçµæœã®ã¾ã¨ã‚")

    # å¤§åˆ†é¡ã§æœ€ã‚‚é‡è¦–ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’ç‰¹å®š
    top_category = labels_main[np.argmax(priorities_main)]

    # å°åˆ†é¡ã®ä¸­ã§æœ€ã‚‚é‡è¦–ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’ç‰¹å®š
    if top_category in all_priorities:
        top_sub = max(all_priorities[top_category].items(), key=lambda x: x[1])[0]
        st.markdown(f"""
        ã‚ãªãŸãŒæœ€ã‚‚é‡è¦–ã—ã¦ã„ã‚‹ã®ã¯ **ã€Œ{top_category}ã€** ã§ã™ã€‚  
        ãã®ä¸­ã§ã‚‚ç‰¹ã« **ã€Œ{top_sub}ã€** ã‚’é‡è¦–ã—ã¦ã„ã‚‹å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚
        """)
    else:
        st.info("å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å…¥åŠ›ãŒå®Œäº†ã™ã‚‹ã¨ã€çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")


# â‘£ æŠ•è³‡ææ¡ˆ
@st.cache_data
def load_data():
    return pd.read_excel("ã‚¹ã‚³ã‚¢ä»˜ãESGãƒ‡ãƒ¼ã‚¿ - ã‚³ãƒ”ãƒ¼.xlsx", sheet_name="Sheet1")


import os
import json
import streamlit as st
import pandas as pd
from google.oauth2 import service_account
import gspread

# --- Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ---
@st.cache_data
def load_data():
    return pd.read_excel("ã‚¹ã‚³ã‚¢ä»˜ãESGãƒ‡ãƒ¼ã‚¿ - ã‚³ãƒ”ãƒ¼.xlsx", sheet_name="Sheet1")

df = load_data()

# --- Google Sheets èªè¨¼ ---
scope = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]

try:
    # âœ… Streamlit Cloud ã¾ãŸã¯ secrets.toml ã«èªè¨¼æƒ…å ±ãŒã‚ã‚‹å ´åˆ
    creds = service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"],
        scopes=scope
    )
    st.write("âœ… èªè¨¼: Streamlit Secrets çµŒç”±ã§æˆåŠŸã—ã¾ã—ãŸã€‚")
# except Exception as e:
#     # âœ… ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
#     # st.warning("âš ï¸ Streamlit SecretsãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®credentials.jsonã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
#     with open("credentials.json", "r") as f:
#         creds_json = json.load(f)
#     creds = service_account.Credentials.from_service_account_info(
#         creds_json,
#         scopes=scope
#     )

# --- gspreadã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ ---
gc = gspread.authorize(creds)

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š ---
spreadsheet = gc.open_by_url("https://docs.google.com/spreadsheets/d/1WVOWgp5Q4TlQu_HhX3TJ5F0beSw1zkcZfcxiiVhn3Yk/edit?gid=0#gid=0")
worksheet = spreadsheet.sheet1  # æœ€åˆã®ã‚·ãƒ¼ãƒˆã‚’é¸æŠ

# st.write("âœ… Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ¥ç¶šã—ã¾ã—ãŸã€‚")



with tabs[3]:
    st.header("æŠ•è³‡å…ˆææ¡ˆ")
    st.subheader("æŠ•è³‡å…ˆã®ä¼æ¥­")


    all_labels = (
        list(all_priorities["ç’°å¢ƒ"].keys())
        + list(all_priorities["ç¤¾ä¼š"].keys())
        + list(all_priorities["ã‚¬ãƒãƒŠãƒ³ã‚¹"].keys())
    )

    # AHPã§æ±ºå®šã—ãŸé‡ã¿ï¼ˆå¤§åˆ†é¡ Ã— å°åˆ†é¡ï¼‰
    weights = []
    for i, group in enumerate(all_priorities.keys()):
        for label, sub_weight in all_priorities[group].items():
            total_weight = priorities_main[i] * sub_weight
            weights.append(total_weight)

    # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    dummy_csr = pd.DataFrame({
        "ä¼æ¥­å": df["ç¤¾å"],
        "æ°—å€™å¤‰å‹•": df["COâ‚‚ã‚¹ã‚³ã‚¢"],
        "è³‡æºå¾ªç’°ãƒ»å¾ªç’°çµŒæ¸ˆ": df["å»ƒæ£„ç‰©ã‚¹ã‚³ã‚¢"],
        "ç”Ÿç‰©å¤šæ§˜æ€§": df["ç”Ÿç‰©å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢"],
        "è‡ªç„¶è³‡æº": df["è‡ªç„¶è³‡æºã‚¹ã‚³ã‚¢"] if "è‡ªç„¶è³‡æºã‚¹ã‚³ã‚¢" in df.columns else 0,
        "äººæ¨©ãƒ»ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³": df["äººæ¨©DDã‚¹ã‚³ã‚¢"],
        "é›‡ç”¨ãƒ»åŠ´åƒæ…£è¡Œ": df["æœ‰ä¼‘ã‚¹ã‚³ã‚¢"],
        "å¤šæ§˜æ€§ãƒ»å…¬å¹³æ€§": df["å¥³æ€§æ¯”ç‡ã‚¹ã‚³ã‚¢"],
        "å–ç· å½¹ä¼šæ§‹æˆãƒ»å°‘æ•°æ ªä¸»ä¿è­·": df["å–ç· å½¹è©•ä¾¡ã‚¹ã‚³ã‚¢"],
        "çµ±æ²»ã¨ãƒªã‚¹ã‚¯ç®¡ç†": df["å†…éƒ¨é€šå ±ã‚¹ã‚³ã‚¢"]
    })

    # æ¬ æå€¤ã‚’0ã§è£œå®Œ
    dummy_csr = dummy_csr.fillna(0)

    # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå¤§åˆ†é¡Ã—å°åˆ†é¡ã®é‡ã¿ã‚’åæ˜ ï¼‰
    dummy_csr["ã‚¹ã‚³ã‚¢"] = dummy_csr[all_labels].dot(weights)

    # ä¸Šä½10ç¤¾è¡¨ç¤º
    result = dummy_csr.sort_values("ã‚¹ã‚³ã‚¢", ascending=False).head(3)
    st.dataframe(result[["ä¼æ¥­å", "ã‚¹ã‚³ã‚¢"]])

    # ==========================
    # åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ï¼ˆCSVã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨ï¼‰
    # ==========================
    st.subheader("åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢")

    try:
        df_price = pd.read_csv("CSRä¼æ¥­_æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆé€±æ¬¡ï¼‰.csv", index_col=0, parse_dates=True)
    except FileNotFoundError:
        st.error("é€±æ¬¡æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        try:
            # â˜… CSVã®åˆ—åï¼ˆä¼æ¥­åï¼‰ãŒ AHP ã®çµæœã¨ä¸€è‡´ã—ã¦ã„ã‚‹å‰æ
            selected_companies = result["ä¼æ¥­å"].tolist()
            df_price = df_price[selected_companies].dropna()
        except KeyError as e:
            st.error(f"æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã«ä¸€è‡´ã—ãªã„ä¼æ¥­åãŒã‚ã‚Šã¾ã™: {e}")
        else:
            # ãƒªã‚¿ãƒ¼ãƒ³ã¨åˆ†æ•£å…±åˆ†æ•£ã‚’è¨ˆç®—ï¼ˆé€±æ¬¡ãªã®ã§ frequency=52ï¼‰
            returns = df_price.pct_change().dropna()
            mu = expected_returns.mean_historical_return(df_price, frequency=52)
            S = risk_models.sample_cov(df_price, frequency=52)
            

            # æœ€é©ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§ï¼‰
            ef = EfficientFrontier(mu, S)
            weights = ef.max_sharpe()
            cleaned_weights = ef.clean_weights()

            st.subheader("æœ€é©ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§ï¼‰")
            for stock, weight in cleaned_weights.items():
                if weight > 0:
                    st.write(f"{stock}: {weight:.2%}")

            # åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’æç”»
            ef_plot = EfficientFrontier(mu, S)
            fig, ax = plt.subplots()
            plotting.plot_efficient_frontier(ef_plot, ax=ax, show_assets=False)

            # ===== ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®è¿½åŠ  =====
            n_samples = 1000
            n_assets = len(mu)
            port_returns = []
            port_volatility = []

            # for _ in range(n_samples):
            #     weights = np.random.random(n_assets)
            #     weights /= np.sum(weights)
            #     ret = np.dot(weights, mu)
            #     vol = np.sqrt(np.dot(weights.T, np.dot(S, weights)))
            #     port_returns.append(ret)
            #     port_volatility.append(vol)

            # for _ in range(n_samples):
            #     # ã¾ãšå…¨ã¦ã‚¼ãƒ­ã«ã™ã‚‹
            #     weights = np.zeros(n_assets)

            #     # ãƒ©ãƒ³ãƒ€ãƒ ã«ä½¿ã†éŠ˜æŸ„ã‚’é¸ã¶ï¼ˆ1ç¤¾ã ã‘ã§ã‚‚OKã€æœ€å¤§ã§å…¨ç¤¾ï¼‰
            #     selected = np.random.choice(n_assets, size=np.random.randint(1, n_assets+1), replace=False)

            #     # é¸ã‚“ã éŠ˜æŸ„ã«ã ã‘é‡ã¿ã‚’å‰²ã‚Šå½“ã¦ã‚‹
            #     random_vals = np.random.random(len(selected))
            #     random_vals /= np.sum(random_vals)
            #     weights[selected] = random_vals

            #     # ãƒªã‚¿ãƒ¼ãƒ³ã¨ãƒªã‚¹ã‚¯ã‚’è¨ˆç®—
            #     ret = np.dot(weights, mu)
            #     vol = np.sqrt(np.dot(weights.T, np.dot(S, weights)))

            #     port_returns.append(ret)
            #     port_volatility.append(vol)

            # ax.scatter(port_volatility, port_returns, c="lightblue", alpha=0.3, s=10, label="ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª")

            # ===== ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®è¿½åŠ  =====
            num_portfolios = 10000
            results = np.zeros((3, num_portfolios))  # 0è¡Œ=ãƒªã‚¿ãƒ¼ãƒ³, 1è¡Œ=ãƒªã‚¹ã‚¯, 2è¡Œ=ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª

            for i in range(num_portfolios):
                weights = np.random.random(len(mu))       # è³‡ç”£ã”ã¨ã«ä¹±æ•°ã‚’å‰²ã‚Šå½“ã¦
                weights /= np.sum(weights)                # åˆè¨ˆã‚’1ã«æ­£è¦åŒ–

                # ãƒªã‚¿ãƒ¼ãƒ³ã¨ãƒªã‚¹ã‚¯ã‚’è¨ˆç®—
                portfolio_return = np.dot(weights, mu)
                portfolio_stddev = np.sqrt(np.dot(weights.T, np.dot(S, weights)))

                # ç„¡ãƒªã‚¹ã‚¯åˆ©å­ç‡ã‚’ä»®å®šã—ã¦ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã‚’è¨ˆç®—ï¼ˆä¾‹ï¼š2%ï¼‰
                sharpe_ratio = (portfolio_return - 0.02) / portfolio_stddev

                # çµæœã‚’æ ¼ç´
                results[0, i] = portfolio_return
                results[1, i] = portfolio_stddev
                results[2, i] = sharpe_ratio

            # æ•£å¸ƒå›³ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
            ax.scatter(results[1, :], results[0, :], c="lightblue", alpha=0.3, s=10, label="ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª")
            # =========================================

            # =========================================

            # ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©ã‚’ä»®å®šï¼ˆä¾‹ï¼š2%ï¼‰
            risk_free_rate = 0.02
            ef = EfficientFrontier(mu, S)
            ef.max_sharpe(risk_free_rate=risk_free_rate)
            ret_tangent, std_tangent, _ = ef.portfolio_performance()

            # è³‡æœ¬å¸‚å ´ç·š
            x = np.linspace(0, std_tangent * 1.5, 100)
            y = risk_free_rate + (ret_tangent - risk_free_rate) / std_tangent * x
            ax.plot(x, y, "b-", label="è³‡æœ¬å¸‚å ´ç·š")

            # ç„¡ãƒªã‚¹ã‚¯è³‡ç”£ï¼ˆç‚¹Aï¼‰
            ax.scatter(0, risk_free_rate, marker="o", s=100, c="g", label="ç„¡ãƒªã‚¹ã‚¯è³‡ç”£ï¼ˆç‚¹Aï¼‰")

            # æœ€å¤§ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªç‚¹ï¼ˆç‚¹Bï¼‰
            ax.scatter(std_tangent, ret_tangent, marker="*", s=200, c="r", label="æœ€å¤§ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªç‚¹ï¼ˆç‚¹Bï¼‰")

            # å‡¡ä¾‹ã‚’æ—¥æœ¬èªã«
            handles, labels = ax.get_legend_handles_labels()
            label_map = {"Efficient frontier": "åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢", "assets": "è³‡ç”£"}
            labels = [label_map.get(l, l) for l in labels]
            ax.legend(handles, labels, loc="best")

            # ã‚¿ã‚¤ãƒˆãƒ«ã¨è»¸ãƒ©ãƒ™ãƒ«
            ax.set_title("åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨è³‡æœ¬å¸‚å ´ç·š")
            ax.set_xlabel("ãƒªã‚¹ã‚¯ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰")
            ax.set_ylabel("ãƒªã‚¿ãƒ¼ãƒ³")

            # âœ… æœ€å¾Œã«1å›ã ã‘æç”»
            st.pyplot(fig)

            # =====================
            # Google Sheetsã«ä¿å­˜ï¼ˆãƒœã‚¿ãƒ³ã§å®Ÿè¡Œï¼‰
            # =====================
            if st.button("ä¿å­˜"):
                # Big Fiveï¼ˆå¹³å‡å€¤ã‚’ä½¿ã†ï¼‰
                bigfive_values = [trait_scores.get(trait, 0) for trait in ["å¤–å‘æ€§", "èª å®Ÿæ€§", "æƒ…ç·’ä¸å®‰å®šæ€§", "é–‹æ”¾æ€§", "èª¿å’Œæ€§"]]

                # å¤§åˆ†é¡AHPï¼ˆç’°å¢ƒãƒ»ç¤¾ä¼šãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹ã®é‡ã¿ï¼‰
                main_priorities_values = list(priorities_main)

                # å°åˆ†é¡AHPï¼ˆall_prioritiesã®å€¤ã‚’é †ç•ªã«å±•é–‹ï¼‰
                sub_priorities_values = []
                for group in ["ç’°å¢ƒ", "ç¤¾ä¼š", "ã‚¬ãƒãƒŠãƒ³ã‚¹"]:
                    sub_priorities_values.extend(all_priorities[group].values())

                # ä¸Šä½3ç¤¾ï¼ˆä¼æ¥­åã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§é€£çµï¼‰
                top3_companies = ", ".join(result["ä¼æ¥­å"].tolist())

                # æœ€é©ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªï¼ˆéŠ˜æŸ„:æ¯”ç‡ ã‚’æ–‡å­—åˆ—åŒ–ï¼‰
                portfolio_str = ", ".join([f"{stock}:{weight:.2%}" for stock, weight in cleaned_weights.items() if weight > 0])

                # 1è¡Œã«ã¾ã¨ã‚ã‚‹
                row_data = [
                    name,
                    age,
                    job,
                    *bigfive_values,
                    *main_priorities_values,
                    *sub_priorities_values,
                    top3_companies,
                    portfolio_str
                ]

                # ã‚·ãƒ¼ãƒˆã«1è¡Œè¿½åŠ 
                worksheet.append_row(row_data, value_input_option="USER_ENTERED")

                st.success("ä¿å­˜ã—ã¾ã—ãŸï¼")










