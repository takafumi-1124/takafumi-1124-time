# === seaborn-deepã‚¨ãƒ©ãƒ¼å®Œå…¨å›é¿ï¼ˆStreamlit Cloudå®‰å®šç‰ˆï¼‰ ===
import matplotlib.pyplot as plt
import matplotlib as mpl
try:
    plt.style.use("seaborn-deep")
except OSError:
    print("âš  seaborn-deep style not available on Streamlit Cloud. Using default style instead.")
    plt.style.use("default")
mpl.rcParams.update(mpl.rcParamsDefault)
mpl.rcParams["axes.unicode_minus"] = False

# === é€šå¸¸ã®import ===
import streamlit as st
import pandas as pd
import numpy as np
import itertools
import matplotlib.style as mstyle
import seaborn as sns
from pypfopt import expected_returns, risk_models, EfficientFrontier, plotting
import japanize_matplotlib
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from google.oauth2 import service_account
import json
import os


# ==============================
# å…±é€šé–¢æ•°
# ==============================

def get_dynamic_scale_labels(left: str, right: str):
    return [
        f"{left}ãŒéå¸¸ã«é‡è¦",
        f"{left}ãŒã‹ãªã‚Šé‡è¦",
        f"{left}ãŒå°‘ã—é‡è¦",
        "åŒã˜ãã‚‰ã„é‡è¦",
        f"{right}ãŒå°‘ã—é‡è¦",
        f"{right}ãŒã‹ãªã‚Šé‡è¦",
        f"{right}ãŒéå¸¸ã«é‡è¦"
    ]


# def get_dynamic_scale_labels(left: str, right: str):
#     return [
#         f"{left}ãŒåœ§å€’çš„ã«é‡è¦", f"{left}ãŒéå¸¸ã«é‡è¦", f"{left}ãŒã‹ãªã‚Šé‡è¦", f"{left}ãŒå°‘ã—é‡è¦",
#         "åŒã˜ãã‚‰ã„é‡è¦",
#         f"{right}ãŒå°‘ã—é‡è¦", f"{right}ãŒã‹ãªã‚Šé‡è¦", f"{right}ãŒéå¸¸ã«é‡è¦", f"{right}ãŒåœ§å€’çš„ã«é‡è¦"
#     ]

def get_dynamic_label_to_value(left: str, right: str):
    # 7æ®µéšAHPã‚¹ã‚±ãƒ¼ãƒ«
    values = [7, 5, 3, 1, 1/3, 1/5, 1/7]
    labels = get_dynamic_scale_labels(left, right)
    return dict(zip(labels, values))


# def get_dynamic_label_to_value(left: str, right: str):
#     values = [9, 7, 5, 3, 1, 1/3, 1/5, 1/7, 1/9]
#     labels = get_dynamic_scale_labels(left, right)
#     return dict(zip(labels, values))

def ahp_calculation(pairwise_matrix):
    n = pairwise_matrix.shape[0]
    geo_means = np.prod(pairwise_matrix, axis=1) ** (1/n)
    priorities = geo_means / np.sum(geo_means)
    weighted_sum = np.dot(pairwise_matrix, priorities)
    lamda_max = np.sum(weighted_sum / priorities) / n
    CI = (lamda_max - n) / (n - 1)
    RI_dict = {1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}
    CR = CI / RI_dict[n]
    return priorities, CR

# ==============================
# Streamlitæœ¬ä½“
# ==============================
st.set_page_config(page_title="ESGæŠ•è³‡æ„æ€æ±ºå®š", layout="centered")
st.title("ğŸŒ± ESGæŠ•è³‡æ„æ€æ±ºå®šã‚µã‚¤ãƒˆ")

tabs = st.tabs(["â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±", "â‘¡ Big Five è¨ºæ–­", "â‘¢ ESGå„ªå…ˆåº¦æ¸¬å®š", "â‘£ æŠ•è³‡ææ¡ˆ"])
all_priorities = {}

# --- â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ± ---
with tabs[0]:
    st.header("ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›")
    name = st.text_input("åå‰", key="name")
    age = st.number_input("å¹´é½¢", 10, 100, 20, key="age")
    job = st.text_input("ã‚ãªãŸã®è·æ¥­ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šå¤§å­¦ç”Ÿ")

# --- â‘¡ Big Five ---
with tabs[1]:
    st.header("Big Five è¨ºæ–­")
    st.markdown("ä»¥ä¸‹ã®å„é …ç›®ã«ã¤ã„ã¦ã€ã€Œéå¸¸ã«å½“ã¦ã¯ã¾ã‚‹ï¼ˆ5ï¼‰ã€ã‹ã‚‰ã€Œã¾ã£ãŸãå½“ã¦ã¯ã¾ã‚‰ãªã„ï¼ˆ1ï¼‰ã€ã¾ã§ã®5æ®µéšã§è©•ä¾¡ã—ã¦ãã ã•ã„")

    bigfive_items = [
        ("ç„¡å£ãª", "å¤–å‘æ€§", True), ("ç¤¾äº¤çš„", "å¤–å‘æ€§", False), ("è©±å¥½ã", "å¤–å‘æ€§", False),
        ("å¤–å‘çš„", "å¤–å‘æ€§", False), ("é™½æ°—ãª", "å¤–å‘æ€§", False),
        ("ã„ã„åŠ æ¸›ãª", "èª å®Ÿæ€§", True), ("ãƒ«ãƒ¼ã‚ºãª", "èª å®Ÿæ€§", True), ("æˆã‚Šè¡Œãã¾ã‹ã›", "èª å®Ÿæ€§", True),
        ("æ€ æƒ°ãª", "èª å®Ÿæ€§", False), ("è¨ˆç”»æ€§ã®ã‚ã‚‹", "èª å®Ÿæ€§", False), ("è»½ç‡ãª", "èª å®Ÿæ€§", False),
        ("å‡ å¸³é¢", "èª å®Ÿæ€§", False),
        ("ä¸å®‰ã«ãªã‚Šã‚„ã™ã„", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("å¿ƒé…æ€§", "æƒ…ç·’ä¸å®‰å®šæ€§", False),
        ("å¼±æ°—ã«ãªã‚‹", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("ç·Šå¼µã—ã‚„ã™ã„", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("æ†‚é¬±ãª", "æƒ…ç·’ä¸å®‰å®šæ€§", False),
        ("å¤šæ‰ã®", "é–‹æ”¾æ€§", False), ("é€²æ­©çš„", "é–‹æ”¾æ€§", False), ("ç‹¬å‰µçš„ãª", "é–‹æ”¾æ€§", True),
        ("é ­ã®å›è»¢ã®é€Ÿã„", "é–‹æ”¾æ€§", False), ("èˆˆå‘³ã®åºƒã„", "é–‹æ”¾æ€§", False), ("å¥½å¥‡å¿ƒãŒå¼·ã„", "é–‹æ”¾æ€§", False),
        ("çŸ­æ°—", "èª¿å’Œæ€§", True), ("æ€’ã‚Šã£ã½ã„", "èª¿å’Œæ€§", True), ("æ¸©å’Œãª", "èª¿å’Œæ€§", False),
        ("å¯›å¤§ãª", "èª¿å’Œæ€§", False), ("è‡ªå·±ä¸­å¿ƒçš„", "èª¿å’Œæ€§", True), ("è¦ªåˆ‡ãª", "èª¿å’Œæ€§", False),
    ]

    # scores = {}
    # for item, trait, reverse in bigfive_items:
    #     val = st.slider(f"{item}", 1, 5, 3, key=f"bf_{item}")
    #     if reverse:
    #         val = 6 - val
    #     scores.setdefault(trait, []).append(val)

    scores = {}
    for idx, (item, trait, reverse) in enumerate(bigfive_items, start=1):
        label = f"**{idx}. {item}**"  # â† å¤ªå­—ã§ç•ªå·ä»˜ã
        val = st.slider(label, 1, 5, 3, key=f"bf_{idx}_{item}")
        if reverse:
            val = 6 - val
        scores.setdefault(trait, []).append(val)



    trait_scores = {k: np.mean(v) for k, v in scores.items()}
    st.subheader("Big Five ã‚¹ã‚³ã‚¢")
    st.dataframe(pd.DataFrame(trait_scores.items(), columns=["æ€§æ ¼ç‰¹æ€§", "ã‚¹ã‚³ã‚¢"]))

# --- â‘¢ AHP ---
with tabs[2]:
    st.header("ESGå„ªå…ˆåº¦æ¸¬å®š")
    st.markdown("""
    ä»¥ä¸‹ã®é …ç›®ã§ã¯ã€2ã¤ã®è¦ç´ ãŒä¸¦ã‚“ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚  
    ãƒãƒ¼ã®ä½ç½®ã‚’å·¦å³ã«å‹•ã‹ã—ã¦ã€ã©ã¡ã‚‰ã‚’ã©ã®ç¨‹åº¦å„ªå…ˆã™ã‚‹ã‹ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
    """)

    labels_main = ['ç’°å¢ƒ', 'ç¤¾ä¼š', 'ã‚¬ãƒãƒŠãƒ³ã‚¹']
    matrix_main = np.ones((3, 3))

    for i, row in enumerate(labels_main):
        for j, col in enumerate(labels_main):
            if i < j:
                labels = get_dynamic_scale_labels(row, col)
                mapping = get_dynamic_label_to_value(row, col)
                selected = st.select_slider(
                    f"{row} vs {col}", options=labels,
                    key=f"main_{row}_{col}", value="åŒã˜ãã‚‰ã„é‡è¦"
                )
                matrix_main[i][j] = mapping[selected]
                matrix_main[j][i] = 1 / mapping[selected]

    priorities_main, cr_main = ahp_calculation(matrix_main)
    st.dataframe(pd.DataFrame({"é …ç›®": labels_main, "å„ªå…ˆåº¦": priorities_main}))
    st.write(f"æ•´åˆæ€§æ¯”ç‡ (CR): {cr_main:.3f}")

    for group_name, group_items in {
        "ç’°å¢ƒ": ['æ°—å€™å¤‰å‹•', 'è³‡æºå¾ªç’°ãƒ»å¾ªç’°çµŒæ¸ˆ', 'ç”Ÿç‰©å¤šæ§˜æ€§', 'è‡ªç„¶è³‡æº'],
        "ç¤¾ä¼š": ['äººæ¨©ãƒ»ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³', 'é›‡ç”¨ãƒ»åŠ´åƒæ…£è¡Œ', 'å¤šæ§˜æ€§ãƒ»å…¬å¹³æ€§'],
        "ã‚¬ãƒãƒŠãƒ³ã‚¹": ['å–ç· å½¹ä¼šæ§‹æˆãƒ»å°‘æ•°æ ªä¸»ä¿è­·', 'çµ±æ²»ã¨ãƒªã‚¹ã‚¯ç®¡ç†']
    }.items():
        st.subheader(f"{group_name}ã®å„ªå…ˆåº¦æ¸¬å®š")
        size = len(group_items)
        matrix = np.ones((size, size))
        for i in range(size):
            for j in range(i + 1, size):
                labels = get_dynamic_scale_labels(group_items[i], group_items[j])
                mapping = get_dynamic_label_to_value(group_items[i], group_items[j])
                selected = st.select_slider(
                    f"{group_items[i]} vs {group_items[j]}",
                    options=labels,
                    key=f"{group_name}_{i}_{j}",
                    value="åŒã˜ãã‚‰ã„é‡è¦"
                )
                matrix[i][j] = mapping[selected]
                matrix[j][i] = 1 / mapping[selected]

        priorities, cr = ahp_calculation(matrix)
        st.dataframe(pd.DataFrame({"é …ç›®": group_items, "å„ªå…ˆåº¦": priorities}))
        st.write(f"æ•´åˆæ€§æ¯”ç‡ (CR): {cr:.3f}")
        all_priorities[group_name] = dict(zip(group_items, priorities))

    st.divider()
    st.subheader("AHPçµæœã®ã¾ã¨ã‚")
    top_category = labels_main[np.argmax(priorities_main)]
    if top_category in all_priorities:
        top_sub = max(all_priorities[top_category].items(), key=lambda x: x[1])[0]
        st.markdown(f"""
        ã‚ãªãŸãŒæœ€ã‚‚é‡è¦–ã—ã¦ã„ã‚‹ã®ã¯ **ã€Œ{top_category}ã€** ã§ã™ã€‚  
        ãã®ä¸­ã§ã‚‚ç‰¹ã« **ã€Œ{top_sub}ã€** ã‚’é‡è¦–ã—ã¦ã„ã‚‹å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚
        """)

# --- â‘£ æŠ•è³‡ææ¡ˆ ---
with tabs[3]:
    st.header("æŠ•è³‡å…ˆææ¡ˆ")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_excel("ã‚¹ã‚³ã‚¢ä»˜ãESGãƒ‡ãƒ¼ã‚¿ - ã‚³ãƒ”ãƒ¼.xlsx", sheet_name="Sheet1")

    all_labels = (
        list(all_priorities["ç’°å¢ƒ"].keys())
        + list(all_priorities["ç¤¾ä¼š"].keys())
        + list(all_priorities["ã‚¬ãƒãƒŠãƒ³ã‚¹"].keys())
    )

    weights = []
    for i, group in enumerate(all_priorities.keys()):
        for label, sub_weight in all_priorities[group].items():
            total_weight = priorities_main[i] * sub_weight
            weights.append(total_weight)

    dummy_csr = pd.DataFrame({
        "ä¼æ¥­å": df["ç¤¾å"],
        "æ°—å€™å¤‰å‹•": df["COâ‚‚ã‚¹ã‚³ã‚¢"],
        "è³‡æºå¾ªç’°ãƒ»å¾ªç’°çµŒæ¸ˆ": df["å»ƒæ£„ç‰©ã‚¹ã‚³ã‚¢"],
        "ç”Ÿç‰©å¤šæ§˜æ€§": df["ç”Ÿç‰©å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢"],
        "è‡ªç„¶è³‡æº": df.get("è‡ªç„¶è³‡æºã‚¹ã‚³ã‚¢", 0),
        "äººæ¨©ãƒ»ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³": df["äººæ¨©DDã‚¹ã‚³ã‚¢"],
        "é›‡ç”¨ãƒ»åŠ´åƒæ…£è¡Œ": df["æœ‰ä¼‘ã‚¹ã‚³ã‚¢"],
        "å¤šæ§˜æ€§ãƒ»å…¬å¹³æ€§": df["å¥³æ€§æ¯”ç‡ã‚¹ã‚³ã‚¢"],
        "å–ç· å½¹ä¼šæ§‹æˆãƒ»å°‘æ•°æ ªä¸»ä¿è­·": df["å–ç· å½¹è©•ä¾¡ã‚¹ã‚³ã‚¢"],
        "çµ±æ²»ã¨ãƒªã‚¹ã‚¯ç®¡ç†": df["å†…éƒ¨é€šå ±ã‚¹ã‚³ã‚¢"]
    }).fillna(0)

    dummy_csr["ã‚¹ã‚³ã‚¢"] = dummy_csr[all_labels].dot(weights)
    result = dummy_csr.sort_values("ã‚¹ã‚³ã‚¢", ascending=False).head(3)
    st.dataframe(result[["ä¼æ¥­å", "ã‚¹ã‚³ã‚¢"]])

    # === æ ªä¾¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ===
    df_price = pd.read_csv("CSRä¼æ¥­_æ ªä¾¡ãƒ‡ãƒ¼ã‚¿_UTF-8ï¼ˆé€±æ¬¡ï¼‰.csv, index_col=0, parse_dates=True)
    selected_companies = result["ä¼æ¥­å"].tolist()
    df_price = df_price[selected_companies].dropna()

    # === å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã¨å…±åˆ†æ•£ ===
    mu = expected_returns.mean_historical_return(df_price, frequency=52)
    S = risk_models.sample_cov(df_price, frequency=52)

        # ===== åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ï¼ˆCSVã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨ï¼‰ =====
    st.subheader("åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢")

    # === å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã¨å…±åˆ†æ•£ã‚’è¨ˆç®— ===
    mu = expected_returns.mean_historical_return(df_price, frequency=52)
    S = risk_models.sample_cov(df_price, frequency=52)

    # ===== æœ€é©ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§ï¼‰ =====
    ef_sharpe = EfficientFrontier(mu, S)  # â† æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    ef_sharpe.max_sharpe()
    cleaned_weights = ef_sharpe.clean_weights()

    st.subheader("æœ€é©ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§ï¼‰")
    for stock, weight in cleaned_weights.items():
        if weight > 0:
            st.write(f"{stock}: {weight:.2%}")


    # ===== åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®æç”» =====
    ef_plot = EfficientFrontier(mu, S)  # â† åˆ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§æç”»
    fig, ax = plt.subplots(figsize=(7, 5))

    mpl.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'IPAexGothic', 'Hiragino Sans']
    mpl.rcParams['axes.unicode_minus'] = False

    plotting.plot_efficient_frontier(ef_plot, ax=ax, show_assets=False)

    ef_plot = EfficientFrontier(mu, S)
    fig, ax = plt.subplots(figsize=(7, 5))

    mpl.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'IPAexGothic', 'Hiragino Sans']
    mpl.rcParams['axes.unicode_minus'] = False

    # --- åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ï¼ˆç·šï¼‰ã‚’æç”» ---
    plotting.plot_efficient_frontier(ef_plot, ax=ax, show_assets=False)

    # === ğŸŸ¢ ã“ã“ã«ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’è²¼ã‚Šä»˜ã‘ï¼ ===
    # ===== ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®è¿½åŠ  =====
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))  # [ãƒªã‚¿ãƒ¼ãƒ³, ãƒªã‚¹ã‚¯, ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª]

    for i in range(num_portfolios):
        weights = np.random.random(len(mu))
        weights /= np.sum(weights)  # åˆè¨ˆãŒ1ã«ãªã‚‹ã‚ˆã†æ­£è¦åŒ–
        
        # å„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒªã‚¿ãƒ¼ãƒ³ãƒ»ãƒªã‚¹ã‚¯ã‚’è¨ˆç®—
        portfolio_return = np.dot(weights, mu)
        portfolio_stddev = np.sqrt(np.dot(weights.T, np.dot(S, weights)))
        
        # ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©ã‚’è€ƒæ…®ã—ãŸã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªï¼ˆä¾‹ï¼š2%ï¼‰
        sharpe_ratio = (portfolio_return - 0.02) / portfolio_stddev
        
        results[0, i] = portfolio_return
        results[1, i] = portfolio_stddev
        results[2, i] = sharpe_ratio

    # === æ•£å¸ƒå›³ã¨ã—ã¦æç”» ===
    ax.scatter(results[1, :], results[0, :],
            c="lightblue", alpha=0.3, s=10,
            label="ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª")


    # ===== è³‡æœ¬å¸‚å ´ç·šãªã©ã‚’è¿½åŠ  =====
    risk_free_rate = 0.02
    ef_tangent = EfficientFrontier(mu, S)  # â† ã¾ãŸæ–°ã—ãä½œã‚‹ï¼
    ef_tangent.max_sharpe(risk_free_rate=risk_free_rate)
    ret_tangent, std_tangent, _ = ef_tangent.portfolio_performance()

    x = np.linspace(0, std_tangent * 1.5, 100)
    y = risk_free_rate + (ret_tangent - risk_free_rate) / std_tangent * x
    ax.plot(x, y, "b-", label="è³‡æœ¬å¸‚å ´ç·š")

    ax.scatter(0, risk_free_rate, c="g", s=100, label="ç„¡ãƒªã‚¹ã‚¯è³‡ç”£ï¼ˆç‚¹Aï¼‰")
    ax.scatter(std_tangent, ret_tangent, c="r", s=200, marker="*", label="æœ€å¤§ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªç‚¹ï¼ˆç‚¹Bï¼‰")

    ax.legend(loc="best")
    ax.set_title("åŠ¹ç‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨è³‡æœ¬å¸‚å ´ç·š")
    ax.set_xlabel("ãƒªã‚¹ã‚¯ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰")
    ax.set_ylabel("ãƒªã‚¿ãƒ¼ãƒ³")

    st.pyplot(fig)

