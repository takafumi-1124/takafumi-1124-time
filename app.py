import matplotlib.pyplot as plt
import matplotlib as mpl
import streamlit as st
import pandas as pd
import numpy as np
import itertools
import matplotlib.style as mstyle
import seaborn as sns # <-- sns.set_styleã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚å¿…é ˆ
import io # <-- ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨

# Google Sheetsé–¢é€£ã®importã¯ã€ä»Šå›žã¯ä½¿ç”¨ã—ãªã„ãŸã‚ãã®ã¾ã¾æ®‹ã—ã¾ã™ãŒã€
# Streamlit Secretsã§èªè¨¼æƒ…å ±ã‚’ç®¡ç†ã™ã‚‹éš›ã«ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from google.oauth2 import service_account
import json
import os
import japanize_matplotlib # æ—¥æœ¬èªžè¡¨ç¤ºã®ãŸã‚

# =======================================================
# seaborn-deepã‚¨ãƒ©ãƒ¼å®Œå…¨å¯¾ç­–ï¼ˆèµ·å‹•æ™‚ã®ç«¶åˆã‚’é¿ã‘ã‚‹ï¼‰
# =======================================================
plt.style.use("default")
mpl.rcParams.update(mpl.rcParamsDefault)

_original_style_use = plt.style.use # çµ„ã¿è¾¼ã¿ã® plt.style.use ã‚’ä¸€åº¦ã ã‘ä¿å­˜
def safe_style_use(style_name):
    # 'seaborn-deep'ã¯Streamlit Cloudã§ã—ã°ã—ã°å•é¡Œã‚’èµ·ã“ã™ãŸã‚ã‚¹ã‚­ãƒƒãƒ—
    if style_name == "seaborn-deep":
        return
    return _original_style_use(style_name)

# Matplotlibã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šé–¢æ•°ã‚’ãƒ‘ãƒƒãƒã™ã‚‹
plt.style.use = safe_style_use
mpl.style.use = safe_style_use

# pypfoptãŒå†…éƒ¨ã§å­˜åœ¨ã—ãªã„ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦ã‚‚ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãªã„ã‚ˆã†ã«ã€åˆ©ç”¨å¯èƒ½ãªã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã
mstyle.available = ["default", "classic", "whitegrid"] 

# seabornã®è¨­å®š
try:
    sns.set_style("whitegrid")
except Exception:
    # seabornãŒãªã„ç’°å¢ƒã§ã‚‚å‹•ãã‚ˆã†ã«ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–
    pass


# ðŸ”¤ æ—¥æœ¬èªžãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
mpl.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'IPAexGothic', 'Hiragino Sans']
mpl.rcParams['axes.unicode_minus'] = False  # ãƒžã‚¤ãƒŠã‚¹ç¬¦å·ã®æ–‡å­—åŒ–ã‘é˜²æ­¢

# ==============================
# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã®ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ä½œæˆé–¢æ•°
# ==============================

@st.cache_data
def load_mock_data():
    """ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€DataFrameã¨ã—ã¦è¿”å´ã™ã‚‹"""
    
    # 1. ã‚¹ã‚³ã‚¢ä»˜ãESGãƒ‡ãƒ¼ã‚¿ ã®ãƒ¢ãƒƒã‚¯
    csr_data = {
        "ç¤¾å": ["ä¼æ¥­A", "ä¼æ¥­B", "ä¼æ¥­C", "ä¼æ¥­D", "ä¼æ¥­E"],
        "COâ‚‚ã‚¹ã‚³ã‚¢": [80, 50, 90, 70, 60],
        "å»ƒæ£„ç‰©ã‚¹ã‚³ã‚¢": [75, 65, 85, 55, 70],
        "ç”Ÿç‰©å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢": [60, 80, 50, 90, 70],
        "äººæ¨©DDã‚¹ã‚³ã‚¢": [90, 70, 80, 60, 75],
        "æœ‰ä¼‘ã‚¹ã‚³ã‚¢": [85, 95, 75, 80, 65],
        "å¥³æ€§æ¯”çŽ‡ã‚¹ã‚³ã‚¢": [70, 80, 90, 60, 50],
        "å–ç· å½¹è©•ä¾¡ã‚¹ã‚³ã‚¢": [80, 70, 60, 90, 50],
        "å†…éƒ¨é€šå ±ã‚¹ã‚³ã‚¢": [75, 65, 85, 70, 90],
    }
    df_csr = pd.DataFrame(csr_data)
    
    # 2. CSRä¼æ¥­_æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆé€±æ¬¡ï¼‰.csv ã®ãƒ¢ãƒƒã‚¯
    np.random.seed(42)
    dates = pd.date_range(start='2020-01-01', periods=100, freq='W')
    price_data = {}
    for company in df_csr["ç¤¾å"]:
        # æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆï¼ˆä¹—æ•°ç³»åˆ—ï¼‰
        base_price = np.random.randint(100, 500)
        returns = np.random.normal(loc=0.001, scale=0.01, size=100)
        prices = base_price * (1 + returns).cumprod()
        price_data[company] = prices
        
    df_price = pd.DataFrame(price_data, index=dates)
    
    return df_csr, df_price

# ã‚¢ãƒ—ãƒªã®é–‹å§‹æ™‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
df_csr, df_price = load_mock_data()


# ==============================
# å…±é€šé–¢æ•° (AHPã‚¹ã‚±ãƒ¼ãƒ«ã¨è¨ˆç®—)
# ==============================

def get_dynamic_scale_labels(left: str, right: str):
    """AHPã®7æ®µéšŽã‚¹ã‚±ãƒ¼ãƒ«ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ"""
    return [
        f"{left}ãŒéžå¸¸ã«é‡è¦",
        f"{left}ãŒã‹ãªã‚Šé‡è¦",
        f"{left}ãŒå°‘ã—é‡è¦",
        "åŒã˜ãã‚‰ã„é‡è¦",
        f"{right}ãŒå°‘ã—é‡è¦",
        f"{right}ãŒã‹ãªã‚Šé‡è¦",
        f"{right}ãŒéžå¸¸ã«é‡è¦"
    ]

def get_dynamic_label_to_value(left: str, right: str):
    """AHPã®ãƒ©ãƒ™ãƒ«ã¨å¯¾å¿œã™ã‚‹æ•°å€¤ï¼ˆé€†æ•°å«ã‚€ï¼‰ã‚’ãƒžãƒƒãƒ”ãƒ³ã‚°"""
    values = [7, 5, 3, 1, 1/3, 1/5, 1/7]
    labels = get_dynamic_scale_labels(left, right)
    return dict(zip(labels, values))

def ahp_calculation(pairwise_matrix):
    """AHPã®é‡ã¿ã¨æ•´åˆæ€§æ¯”çŽ‡ï¼ˆCRï¼‰ã‚’è¨ˆç®—"""
    n = pairwise_matrix.shape[0]
    geo_means = np.prod(pairwise_matrix, axis=1) ** (1/n)
    priorities = geo_means / np.sum(geo_means)
    weighted_sum = np.dot(pairwise_matrix, priorities)
    lamda_max = np.sum(weighted_sum / priorities) / n
    CI = (lamda_max - n) / (n - 1)
    RI_dict = {1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}
    
    if n not in RI_dict or RI_dict[n] == 0:
        CR = 0.0
    else:
        CR = CI / RI_dict[n]
        
    return priorities, CR

# ==============================
# Streamlitæœ¬ä½“
# ==============================
st.set_page_config(page_title="ESGæŠ•è³‡æ„æ€æ±ºå®š", layout="centered")
st.title("ðŸŒ± ESGæŠ•è³‡æ„æ€æ±ºå®šã‚µã‚¤ãƒˆ")

tabs = st.tabs(["â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±", "â‘¡ Big Five è¨ºæ–­", "â‘¢ ESGå„ªå…ˆåº¦æ¸¬å®š", "â‘£ æŠ•è³‡ææ¡ˆ"])
all_priorities = {}

# --- â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ± ---
with tabs[0]:
    st.header("ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›")
    name = st.text_input("åå‰", key="name")
    age = st.number_input("å¹´é½¢", 10, 100, 20, key="age")
    job = st.text_input("ã‚ãªãŸã®è·æ¥­ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šå¤§å­¦ç”Ÿ")

# --- â‘¡ Big Five ---
with tabs[1]:
    st.header("Big Five è¨ºæ–­")
    st.markdown("ä»¥ä¸‹ã®å„é …ç›®ã«ã¤ã„ã¦ã€ã€Œéžå¸¸ã«å½“ã¦ã¯ã¾ã‚‹ï¼ˆ5ï¼‰ã€ã‹ã‚‰ã€Œã¾ã£ãŸãå½“ã¦ã¯ã¾ã‚‰ãªã„ï¼ˆ1ï¼‰ã€ã¾ã§ã®5æ®µéšŽã§è©•ä¾¡ã—ã¦ãã ã•ã„")

    bigfive_items = [
        ("ç„¡å£ãª", "å¤–å‘æ€§", True), ("ç¤¾äº¤çš„", "å¤–å‘æ€§", False), ("è©±å¥½ã", "å¤–å‘æ€§", False),
        ("å¤–å‘çš„", "å¤–å‘æ€§", False), ("é™½æ°—ãª", "å¤–å‘æ€§", False),
        ("ã„ã„åŠ æ¸›ãª", "èª å®Ÿæ€§", True), ("ãƒ«ãƒ¼ã‚ºãª", "èª å®Ÿæ€§", True), ("æˆã‚Šè¡Œãã¾ã‹ã›", "èª å®Ÿæ€§", True),
        ("æ€ æƒ°ãª", "èª å®Ÿæ€§", False), ("è¨ˆç”»æ€§ã®ã‚ã‚‹", "èª å®Ÿæ€§", False), ("è»½çŽ‡ãª", "èª å®Ÿæ€§", False),
        ("å‡ å¸³é¢", "èª å®Ÿæ€§", False),
        ("ä¸å®‰ã«ãªã‚Šã‚„ã™ã„", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("å¿ƒé…æ€§", "æƒ…ç·’ä¸å®‰å®šæ€§", False),
        ("å¼±æ°—ã«ãªã‚‹", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("ç·Šå¼µã—ã‚„ã™ã„", "æƒ…ç·’ä¸å®‰å®šæ€§", False), ("æ†‚é¬±ãª", "æƒ…ç·’ä¸å®‰å®šæ€§", False),
        ("å¤šæ‰ã®", "é–‹æ”¾æ€§", False), ("é€²æ­©çš„", "é–‹æ”¾æ€§", False), ("ç‹¬å‰µçš„ãª", "é–‹æ”¾æ€§", True),
        ("é ­ã®å›žè»¢ã®é€Ÿã„", "é–‹æ”¾æ€§", False), ("èˆˆå‘³ã®åºƒã„", "é–‹æ”¾æ€§", False), ("å¥½å¥‡å¿ƒãŒå¼·ã„", "é–‹æ”¾æ€§", False),
        ("çŸ­æ°—", "èª¿å’Œæ€§", True), ("æ€’ã‚Šã£ã½ã„", "èª¿å’Œæ€§", True), ("æ¸©å’Œãª", "èª¿å’Œæ€§", False),
        ("å¯›å¤§ãª", "èª¿å’Œæ€§", False), ("è‡ªå·±ä¸­å¿ƒçš„", "èª¿å’Œæ€§", True), ("è¦ªåˆ‡ãª", "èª¿å’Œæ€§", False),
    ]

    scores = {}
    for idx, (item, trait, reverse) in enumerate(bigfive_items, start=1):
        label = f"**{idx}. {item}**"
        val = st.slider(label, 1, 5, 3, key=f"bf_{idx}_{item}")
        if reverse:
            val = 6 - val
        scores.setdefault(trait, []).append(val)

    trait_scores = {k: np.mean(v) for k, v in scores.items()}
    st.subheader("Big Five ã‚¹ã‚³ã‚¢")
    st.dataframe(pd.DataFrame(trait_scores.items(), columns=["æ€§æ ¼ç‰¹æ€§", "ã‚¹ã‚³ã‚¢"]))

# --- â‘¢ AHP ---
with tabs[2]:
    st.header("ESGå„ªå…ˆåº¦æ¸¬å®š")
    st.markdown("""
    ä»¥ä¸‹ã®é …ç›®ã§ã¯ã€2ã¤ã®è¦ç´ ãŒä¸¦ã‚“ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚  
    ãƒãƒ¼ã®ä½ç½®ã‚’å·¦å³ã«å‹•ã‹ã—ã¦ã€ã©ã¡ã‚‰ã‚’ã©ã®ç¨‹åº¦å„ªå…ˆã™ã‚‹ã‹ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
    """)

    labels_main = ['ç’°å¢ƒ', 'ç¤¾ä¼š', 'ã‚¬ãƒãƒŠãƒ³ã‚¹']
    matrix_main = np.ones((3, 3))

    for i, row in enumerate(labels_main):
        for j, col in enumerate(labels_main):
            if i < j:
                labels = get_dynamic_scale_labels(row, col)
                mapping = get_dynamic_label_to_value(row, col)
                selected = st.select_slider(
                    f"{row} vs {col}", options=labels,
                    key=f"main_{row}_{col}", value="åŒã˜ãã‚‰ã„é‡è¦"
                )
                matrix_main[i][j] = mapping[selected]
                matrix_main[j][i] = 1 / mapping[selected]

    priorities_main, cr_main = ahp_calculation(matrix_main)
    st.subheader("ä¸»è¦3è¦ç´ ã®å„ªå…ˆåº¦")
    st.dataframe(pd.DataFrame({"é …ç›®": labels_main, "å„ªå…ˆåº¦": priorities_main}))
    st.write(f"æ•´åˆæ€§æ¯”çŽ‡ (CR): {cr_main:.3f}")

    for group_name, group_items in {
        "ç’°å¢ƒ": ['æ°—å€™å¤‰å‹•', 'è³‡æºå¾ªç’°ãƒ»å¾ªç’°çµŒæ¸ˆ', 'ç”Ÿç‰©å¤šæ§˜æ€§', 'è‡ªç„¶è³‡æº'],
        "ç¤¾ä¼š": ['äººæ¨©ãƒ»ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³', 'é›‡ç”¨ãƒ»åŠ´åƒæ…£è¡Œ', 'å¤šæ§˜æ€§ãƒ»å…¬å¹³æ€§'],
        "ã‚¬ãƒãƒŠãƒ³ã‚¹": ['å–ç· å½¹ä¼šæ§‹æˆãƒ»å°‘æ•°æ ªä¸»ä¿è­·', 'çµ±æ²»ã¨ãƒªã‚¹ã‚¯ç®¡ç†']
    }.items():
        st.subheader(f"{group_name}ã®å„ªå…ˆåº¦æ¸¬å®š")
        size = len(group_items)
        matrix = np.ones((size, size))
        for i in range(size):
            for j in range(i + 1, size):
                labels = get_dynamic_scale_labels(group_items[i], group_items[j])
                mapping = get_dynamic_label_to_value(group_items[i], group_items[j])
                selected = st.select_slider(
                    f"{group_items[i]} vs {group_items[j]}",
                    options=labels,
                    key=f"{group_name}_{i}_{j}",
                    value="åŒã˜ãã‚‰ã„é‡è¦"
                )
                matrix[i][j] = mapping[selected]
                matrix[j][i] = 1 / mapping[selected]

        priorities, cr = ahp_calculation(matrix)
        st.dataframe(pd.DataFrame({"é …ç›®": group_items, "å„ªå…ˆåº¦": priorities}))
        st.write(f"æ•´åˆæ€§æ¯”çŽ‡ (CR): {cr:.3f}")
        all_priorities[group_name] = dict(zip(group_items, priorities))

    st.divider()
    st.subheader("AHPçµæžœã®ã¾ã¨ã‚")
    top_category = labels_main[np.argmax(priorities_main)]
    if top_category in all_priorities:
        top_sub = max(all_priorities[top_category].items(), key=lambda x: x[1])[0]
        st.markdown(f"""
        ã‚ãªãŸãŒæœ€ã‚‚é‡è¦–ã—ã¦ã„ã‚‹ã®ã¯ **ã€Œ{top_category}ã€** ã§ã™ã€‚  
        ãã®ä¸­ã§ã‚‚ç‰¹ã« **ã€Œ{top_sub}ã€** ã‚’é‡è¦–ã—ã¦ã„ã‚‹å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚
        """)

# --- â‘£ æŠ•è³‡ææ¡ˆ ---
with tabs[3]:
    st.header("æŠ•è³‡å…ˆææ¡ˆ")

    # ã€pypfoptã®é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã€‘
    # Streamlit Cloudã§ã®seaborn-deep/pypfoptç«¶åˆã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã€
    # styleãƒ‘ãƒƒãƒãŒå®Œå…¨ã«é©ç”¨ã•ã‚ŒãŸå¾Œã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹
    try:
        from pypfopt import expected_returns, risk_models, EfficientFrontier, plotting
        import pypfopt.plotting as pplot
        pplot.plt = plt
    except Exception as e:
        st.error(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚Streamlitç’°å¢ƒã®å•é¡Œã§ã™: {e}")
        st.warning("ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        st.stop()


    # ãƒ‡ãƒ¼ã‚¿ã¯load_mock_dataã§å–å¾—
    df = df_csr 

    # --- ESGã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚° ---
    all_labels = (
        list(all_priorities["ç’°å¢ƒ"].keys())
        + list(all_priorities["ç¤¾ä¼š"].keys())
        + list(all_priorities["ã‚¬ãƒãƒŠãƒ³ã‚¹"].keys())
    )

    weights = []
    for i, group in enumerate(all_priorities.keys()):
        for label, sub_weight in all_priorities[group].items():
            total_weight = priorities_main[i] * sub_weight
            weights.append(total_weight)

    dummy_csr = pd.DataFrame({
        "ä¼æ¥­å": df["ç¤¾å"],
        "æ°—å€™å¤‰å‹•": df["COâ‚‚ã‚¹ã‚³ã‚¢"],
        "è³‡æºå¾ªç’°ãƒ»å¾ªç’°çµŒæ¸ˆ": df["å»ƒæ£„ç‰©ã‚¹ã‚³ã‚¢"],
        "ç”Ÿç‰©å¤šæ§˜æ€§": df["ç”Ÿç‰©å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢"],
        # .get()ã§ã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã«0ã‚’è¿”ã™å‡¦ç†ã‚’å†ç¾
        "è‡ªç„¶è³‡æº": df.get("è‡ªç„¶è³‡æºã‚¹ã‚³ã‚¢", [0] * len(df["ç¤¾å"])), 
        "äººæ¨©ãƒ»ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³": df["äººæ¨©DDã‚¹ã‚³ã‚¢"],
        "é›‡ç”¨ãƒ»åŠ´åƒæ…£è¡Œ": df["æœ‰ä¼‘ã‚¹ã‚³ã‚¢"],
        "å¤šæ§˜æ€§ãƒ»å…¬å¹³æ€§": df["å¥³æ€§æ¯”çŽ‡ã‚¹ã‚³ã‚¢"],
        "å–ç· å½¹ä¼šæ§‹æˆãƒ»å°‘æ•°æ ªä¸»ä¿è­·": df["å–ç· å½¹è©•ä¾¡ã‚¹ã‚³ã‚¢"],
        "çµ±æ²»ã¨ãƒªã‚¹ã‚¯ç®¡ç†": df["å†…éƒ¨é€šå ±ã‚¹ã‚³ã‚¢"]
    })

    dummy_csr["ã‚¹ã‚³ã‚¢"] = dummy_csr[all_labels].dot(weights)
    result = dummy_csr.sort_values("ã‚¹ã‚³ã‚¢", ascending=False).head(3)
    
    st.subheader("å„ªå…ˆåº¦ã®é«˜ã„ESGç‰¹æ€§ã«åŸºã¥ãæŽ¨å¥¨ä¼æ¥­")
    st.dataframe(result[["ä¼æ¥­å", "ã‚¹ã‚³ã‚¢"]])
    
    if len(result) == 0:
        st.warning("æŽ¨å¥¨ä¼æ¥­ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()
        
    # === æ ªä¾¡ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨ ===
    df_price_clean = df_price[result["ä¼æ¥­å"].tolist()].dropna()

    if df_price_clean.empty:
        st.warning("é¸æŠžã•ã‚ŒãŸä¼æ¥­ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã¯ä¼æ¥­A/B/C/D/EãŒä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚")
        st.stop()

    # === å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã¨å…±åˆ†æ•£ ===
    mu = expected_returns.mean_historical_return(df_price_clean, frequency=52)
    S = risk_models.sample_cov(df_price_clean, frequency=52)

    # ===== æœ€é©ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§ï¼‰ =====
    ef_sharpe = EfficientFrontier(mu, S)
    ef_sharpe.max_sharpe(risk_free_rate=0.02)
    cleaned_weights = ef_sharpe.clean_weights()

    st.subheader("æœ€é©ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§ï¼‰")
    weights_df = pd.DataFrame(cleaned_weights.items(), columns=["éŠ˜æŸ„", "æŠ•è³‡æ¯”çŽ‡"])
    weights_df["æŠ•è³‡æ¯”çŽ‡"] = (weights_df["æŠ•è³‡æ¯”çŽ‡"] * 100).map('{:.2f}%'.format)
    weights_df = weights_df[weights_df["æŠ•è³‡æ¯”çŽ‡"] != '0.00%']
    st.dataframe(weights_df, hide_index=True)


    # ===== åŠ¹çŽ‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®æç”» =====
    st.subheader("åŠ¹çŽ‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢")
    
    fig, ax = plt.subplots(figsize=(7, 5))
    
    # æ—¥æœ¬èªžãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆå›³ã«ã‚‚åæ˜ ã•ã›ã‚‹ï¼‰
    mpl.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'IPAexGothic', 'Hiragino Sans']
    mpl.rcParams['axes.unicode_minus'] = False

    # --- åŠ¹çŽ‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ï¼ˆç·šï¼‰ã‚’æç”» ---
    ef_plot = EfficientFrontier(mu, S)
    plotting.plot_efficient_frontier(ef_plot, ax=ax, show_assets=False, lw=2, color='darkgreen')

    # ===== ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®è¿½åŠ  =====
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))  # [ãƒªã‚¿ãƒ¼ãƒ³, ãƒªã‚¹ã‚¯, ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª]

    for i in range(num_portfolios):
        weights_rand = np.random.random(len(mu))
        weights_rand /= np.sum(weights_rand)  # åˆè¨ˆãŒ1ã«ãªã‚‹ã‚ˆã†æ­£è¦åŒ–
        
        # å„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒªã‚¿ãƒ¼ãƒ³ãƒ»ãƒªã‚¹ã‚¯ã‚’è¨ˆç®—
        portfolio_return = np.dot(weights_rand, mu)
        portfolio_stddev = np.sqrt(np.dot(weights_rand.T, np.dot(S, weights_rand)))
        
        # ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©ã‚’è€ƒæ…®ã—ãŸã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªï¼ˆä¾‹ï¼š2%ï¼‰
        sharpe_ratio = (portfolio_return - 0.02) / portfolio_stddev
        
        results[0, i] = portfolio_return
        results[1, i] = portfolio_stddev
        results[2, i] = sharpe_ratio

    # === æ•£å¸ƒå›³ã¨ã—ã¦æç”» ===
    ax.scatter(results[1, :], results[0, :],
               c="lightblue", alpha=0.3, s=10,
               label="ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª")


    # ===== è³‡æœ¬å¸‚å ´ç·šãªã©ã‚’è¿½åŠ  =====
    risk_free_rate = 0.02
    ef_tangent = EfficientFrontier(mu, S) 
    ef_tangent.max_sharpe(risk_free_rate=risk_free_rate)
    ret_tangent, std_tangent, _ = ef_tangent.portfolio_performance()

    # è³‡æœ¬å¸‚å ´ç·š (CML) ã®æç”»
    x = np.linspace(0, std_tangent * 1.5, 100)
    y = risk_free_rate + (ret_tangent - risk_free_rate) / std_tangent * x
    ax.plot(x, y, "b--", label="è³‡æœ¬å¸‚å ´ç·š", alpha=0.7)

    # ç‰¹æ®Šãªç‚¹ã®æç”»
    ax.scatter(0, risk_free_rate, c="g", s=100, label="ç„¡ãƒªã‚¹ã‚¯è³‡ç”£ï¼ˆç‚¹Aï¼‰", zorder=3)
    ax.scatter(std_tangent, ret_tangent, c="r", s=200, marker="*", label="æœ€å¤§ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªç‚¹ï¼ˆç‚¹Bï¼‰", zorder=3)
    
    # è»¸ãƒ©ãƒ™ãƒ«ã¨ã‚¿ã‚¤ãƒˆãƒ«
    ax.set_title("åŠ¹çŽ‡çš„ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨è³‡æœ¬å¸‚å ´ç·š")
    ax.set_xlabel("ãƒªã‚¹ã‚¯ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰")
    ax.set_ylabel("ãƒªã‚¿ãƒ¼ãƒ³")
    ax.legend(loc="upper left")
    ax.grid(True, linestyle='--', alpha=0.6)

    st.pyplot(fig)
    plt.close(fig) # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯é˜²æ­¢ã®ãŸã‚

    st.markdown("""
    ---
    **è£œè¶³:** ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`ã‚¹ã‚³ã‚¢ä»˜ãESGãƒ‡ãƒ¼ã‚¿ - ã‚³ãƒ”ãƒ¼.xlsx` ã¨ `CSRä¼æ¥­_æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆé€±æ¬¡ï¼‰.csv`ï¼‰ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ãƒ†ã‚¹ãƒˆç”¨ã®**ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿**ã‚’ä½¿ç”¨ã—ã¦å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã™ã€‚
    å®Ÿéš›ã«åˆ©ç”¨ã™ã‚‹éš›ã¯ã€é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã‚’Streamlit Cloudã®ç’°å¢ƒã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€Google Sheets APIçµŒç”±ã§èª­ã¿è¾¼ã‚€ã‚ˆã†ã‚³ãƒ¼ãƒ‰ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
    """)
